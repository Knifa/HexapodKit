\chapter{Conclusion}
\label{chap:conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Summary}
Robots are awesome, man.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Further Work}

This final section will detail a number of ways in which the project could be developed further. Much of this additional functionality could be provided by existing standard or community-provided ROS packages, however further research is necessary to prove the adequacy of such packages. Furthermore, some of these suggestions require additional or even entirely new hardware. These would require new drivers, control software, not to mention the hardware integration itself.

\subsection{Improved Actuators}
The actuators currently used in the robot severely limit accuracy and movement speed. While these servos are extremely cheap and have incredible amounts of torque, this comes at the cost of accuracy, speed and build quality. Generally, the robot requires complete calibration every time it is powered on to ensure correct operation, and even after the calibration process it isn't particularly accurate.

Replacing these servos with ones of higher quality would allow the robot to move much more quickly and accurately. As a result, the walking motions implemented by the tripod gait would be smoother in general. This could possibly help with the drift issues occurring in the visual odometry system.

\subsection{Inverse Kinematics}
To improve movements in general, an inverse kinematics system could be added. This system would allow us to specify where the legs should be positioned relative to the ground, rather than implementing a specific sequence for the angles to rotate to. The inverse kinematics system could then calculate which angle to rotate the joints to based on these position. This would allow for much more smoother movements in terms of the walk gait, which may be beneficial to the visual odometry system as mentioned previously.

This allows for much more complex movements over all. For example, the base of the hexapod can be pivoted but in such a way that the legs remain in place. With an inverse kinematics system, we could supply commands that specify this base rotation having to be concerned about the underlying actuator movements. This can then be expanded to implement more complex walking gaits, perhaps even to allow the robot to walk up stairs, for example.

\subsection{Additional Sensor Hardware \& Environment Interpretation}
Additional sensory input would allow the control system to understand the environment surrounding the robot much more clearly. In particular, a pair of accelerometer and gyroscope sensors would be extremely helpful. These sensors would provide data relating to the acceleration and orientation of the robot in 3D space. By combining data from these sensors with the output given by the visual odometry system, it may be possible to improve the accuracy of the positional fix. Furthermore, it may be possible to automatically calibrate the servos by using these sensors as it can be used to give a reading as to when the robot is in a stable upright position.

The RGB-D camera used in the robot---specifically the \emph{ASUS Xtion Pro Live}---also features a pair of microphones. These could be used in some manner to implement voice recognition commands, for example. In particular, it is possible to infer from which direction any sound is coming by comparing times between the input signals of the two microphones. This could be used to implement some sort of follow behaviour based on sound.

\subsection{Untethered \& Cloud Operation}
The robot is only capable of tethered operation in its current hardware configuration. Specifically, a large bundle of cables protrudes from the back of the robot, connecting the RGB-D camera and servo controller to a nearby computer and power source. This restricts the robot to 5 meter radius around the equipment, as USB devices tend to stop functioning correctly with cables above this length without active boosters. 

The decision to limit to tethered operation only was to, primarily, reduce the complexity of the robot hardware itself while the control system was being developed. Batteries require additional circuitry, such as voltage converters and charging circuits. Furthermore, the power requirements for the robot are quite high posing somewhat of a potential health risk, as the robot draws 10A at 6V at full operational speed. Now that a working control system is implemented, these issues are no longer a concern.

Furthermore, the sensing system requires a particularly high performance machine to achieve good results. Even if it were possible to interface with the RGB-D sensor through a microcontroller, it would in no shape or form be able to meet these performance demands.

However, it would be possible to exploit the distributed nature of ROS to alleviate these issues. A Beaglebone Black, for example, could be attached to the robot. This could connect directly to the RGB-D camera and servo controller over USB as the current system does. Subsystems that interface with the hardware would run on this embedded system. Another machine could then be dedicated to performing the complex processing tasks.

This could be further expanded to make use of cloud services such as Amazon EC2 and Microsoft Azure. Rather than running the performance demanding nodes on a physical machine, they could be ran on a number of virtual machines. 