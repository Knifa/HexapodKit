\chapter{Conclusion}
\label{chap:conclusion}

This chapter concludes the report, reviewing our initial objectives and providing an assessment of over all success against these objectives. The chapter will then end with a discussion about any future developments that could be made with the robot and robot control system.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Summary}

The original premise of this project was develop a control system for a hexapod-type robot through the use of the Robot Operating System (ROS). A number of complex behaviours such as environmental mapping and autonomous navigation would be implemented. By doing this, we would evaluate the usefulness of ROS as a means for rapidly developing these control systems in a simplified manner. The large variety of standard and community-provided ROS packages would be explored, and we would attempt to leverage these packages to endow the robot with the complex behaviours described. These packages should have allowed us to implement these behaviours without requiring a deep understanding of their inner workings.

This control system was implemented by dividing the system into a number of subsystems. These subsystems would implement hardware operations, locomotion facilities, sensing facilities and autonomous navigation facilities. While a number of standard and community-provided packages existed which we utilised to implement these subsystems, specifically for the sensing and navigation subsystems, we still had to implement a number of platform specific nodes. These nodes would provide drivers for the servo controller, a means of calibrating the servos, and a means of locomoting the robot through a tripod walk gait. ROS proved to be very useful in simplifying the development of these custom nodes.

An evaluation of the control system showed that the implemented system was fairly functional. All of the nodes which were developed specifically for the our hexapod-type robot worked as intended.  The visual odometery system was shown to drift quite intensely as the robot performed angular motions but was otherwise reasonably accurate in estimating the robot's position in space. The mapping system gave a good facsimile of the surrounding environment, but drift from the visual odometry system tended to cause severe distortions in the resulting generated map. The autonomous navigation system was particularly good at moving the robot along direct paths, even when an obstacle was placed in its path. However, the system was not particularly good at moving along complex paths---i.e., around large obstacles---especially in an unknown environment. The control system tended to take a long time to get the robot to the correct position, and in some cases failed completely.

Overall, the project has been relatively successful. It would have been very difficult to complete this project without the use of ROS. The many standard and community-provided packages allowed us to leverage complex functionalities that would have otherwise required many person hours to implement by hand. Each subsystem could have been considered an entire project of its own right without these packages. Additionally, the development of the custom nodes which were required was accelerated through the use of ROS in general.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Further Work}

This final section will detail a number of ways in which the project could be developed further. Much of this additional functionality could be provided by existing standard or community-provided ROS packages, however further research is necessary to prove the adequacy of such packages. Furthermore, some of these suggestions require additional or even entirely new hardware. These would require new drivers, control software, not to mention the hardware integration itself.

\subsection{Improved Actuators}
The actuators currently used in the robot severely limit accuracy and movement speed. While these servos are extremely cheap and have incredible amounts of torque, this comes at the cost of accuracy, speed and build quality. Generally, the robot requires complete calibration every time it is powered on to ensure correct operation, and even after the calibration process it isn't particularly accurate.

Replacing these servos with ones of higher quality would allow the robot to move much more quickly and accurately. As a result, the walking motions implemented by the tripod gait would be smoother in general. This could possibly help with the drift issues occurring in the visual odometry system.

\subsection{Inverse Kinematics}
To improve movements in general, an inverse kinematics system could be added. This system would allow us to specify where the legs should be positioned relative to the ground, rather than implementing a specific sequence for the angles to rotate to. The inverse kinematics system could then calculate which angle to rotate the joints to based on these position. This would allow for much more smoother movements in terms of the walk gait, which may be beneficial to the visual odometry system as mentioned previously.

This allows for much more complex movements over all. For example, the base of the hexapod can be pivoted but in such a way that the legs remain in place. With an inverse kinematics system, we could supply commands that specify this base rotation having to be concerned about the underlying actuator movements. This can then be expanded to implement more complex walking gaits, perhaps even to allow the robot to walk up stairs, for example.

\subsection{Additional Sensor Hardware \& Environment Interpretation}
Additional sensory input would allow the control system to understand the environment surrounding the robot much more clearly. In particular, a pair of accelerometer and gyroscope sensors would be extremely helpful. These sensors would provide data relating to the acceleration and orientation of the robot in 3D space. By combining data from these sensors with the output given by the visual odometry system, it may be possible to improve the accuracy of the positional fix. Furthermore, it may be possible to automatically calibrate the servos by using these sensors as it can be used to give a reading as to when the robot is in a stable upright position.

The RGB-D camera used in the robot---specifically the \emph{ASUS Xtion Pro Live}---also features a pair of microphones. These could be used in some manner to implement voice recognition commands, for example. In particular, it is possible to infer from which direction any sound is coming by comparing times between the input signals of the two microphones. This could be used to implement some sort of follow behaviour based on sound.

\subsection{Untethered \& Cloud Operation}
The robot is only capable of tethered operation in its current hardware configuration. Specifically, a large bundle of cables protrudes from the back of the robot, connecting the RGB-D camera and servo controller to a nearby computer and power source. This restricts the robot to 5 meter radius around the equipment, as USB devices tend to stop functioning correctly with cables above this length without active boosters. 

The decision to limit to tethered operation only was to, primarily, reduce the complexity of the robot hardware itself while the control system was being developed. Batteries require additional circuitry, such as voltage converters and charging circuits. Furthermore, the power requirements for the robot are quite high posing somewhat of a potential health risk, as the robot draws 10A at 6V at full operational speed. Now that a working control system is implemented, these issues are no longer a concern.

Furthermore, the sensing system requires a particularly high performance machine to achieve good results. Even if it were possible to interface with the RGB-D sensor through a microcontroller, it would in no shape or form be able to meet these performance demands.

However, it would be possible to exploit the distributed nature of ROS to alleviate these issues. A Beaglebone Black, for example, could be attached to the robot. This could connect directly to the RGB-D camera and servo controller over USB as the current system does. Subsystems that interface with the hardware would run on this embedded system. Another machine could then be dedicated to performing the complex processing tasks.

This could be further expanded to make use of cloud services such as Amazon EC2 and Microsoft Azure. Rather than running the performance demanding nodes on a physical machine, they could be ran on a number of virtual machines. 